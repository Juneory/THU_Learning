{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layer\n",
    "\n",
    "마찬가지로 인공 신경망(Artificial Neural Network, ANN)의 한 종류로,층이 많아질수록 더 깊어진다고 해서 '심층' 신경망이라 불립니다.\n",
    "\n",
    "최소한 하나의 은닉층을 가지고 있는 간단한 구조의 일반적인 인공 신경망과는 달리\n",
    "심층 신경망은 은닉층이 2개 이상인 신경망을 의미\n",
    "\n",
    "데이터를 입력받아 층(layer)을 통과하며 각 뉴런(neuron)에서 가중치(weight), 편향(bias), 활성화 함수(activation function)를 사용해 출력값을 계산합니다\n",
    "각 층들의 관계는 데이터의 특징들을 뽑아서 다음 층으로 전달해주는 관계\n",
    "\n",
    "결국 층이 많다는 것은 그만 큼 다양하고 복잡한 연산을 한다는 것\n",
    "\n",
    "db나 엑셀등 정형화된 데이터에 잘 맞는 일반적인 전통적 머신러닝은, \n",
    "\n",
    "딥러닝의 한 부분인 심층 신경망은 데이터의 이미지 처리, 자연어 처리, 음성 인식 등 복잡한 패턴의 비정형화된 데이터를 학습하는 데 뛰어난 성능\n",
    "\n",
    "이미지 처리: Image Processing\n",
    "자연어 처리: Natural Language Processing (NLP)\n",
    "음성 인식: Speech Recognition\n",
    "\n",
    "간단히\n",
    "입력층: 데이터를 네트워크에 전달하는 층.\n",
    "은닉층: 데이터의 패턴과 특징을 학습하는 층.\n",
    "출력층: 예측 결과를 출력하는 층.\n",
    "\n",
    "\n",
    "## Summary() method\n",
    "\n",
    "summary() 메서드는 모델의 구조와 레이어 정보를 출력해주는 함수.\n",
    "\n",
    "Sequential은 Keras에서 제공하는 모델 클래스 중 하나로, 각 레이어끼리 순차적인 구조의 신경망을 정의할 때 사용하였습니다.\n",
    "\n",
    "여기서는 모델의 각 레이어의 이름, 타입, 출력 형태 (shape)를 보여줍니다.\n",
    "\n",
    "파라미터 수: 각 레이어에서 학습 가능한 파라미터(가중치와 편향)의 수를 보여줍니다. 마찬가지로 전체는 전체\n",
    "\n",
    "결과적으로 \n",
    "summary() method 를 사용하여\n",
    "이 신경망 모델은은\n",
    "총 79510개의 weight와 bias으로 학습이 가능한 모델인 것을 알 수 있었습니다.\n",
    "\n",
    "## 렐루\n",
    "\n",
    "아래 그림은 시그모이드활성함수 = 값을 0과 1 사이의 범위로 변환하는 함수, 단점은 선형 출력값이 너무 커지거나 작아지면, 시그모이드 함수값의 변화가 굉장히 작아짐 1,이나0에 가까워짐, = 포화되었다라고 표현 기울기 소실 문제(vanishing gradient problem)\n",
    "\n",
    "이뜻은, 완만하게 기울어 이어지는 구간은 신경망 모델이 빠르게 변화에 대응해서 학습할 수 없게 하는 것 = 레이어를 깊게 쌓을 수 없게함\n",
    "\n",
    "렐루함수 Rectified 수정된\n",
    "비선형성: ReLU는 신경망에 비선형성을 제공하여 복잡한 패턴을 학습할 수 있게 합니다.\n",
    "간단함: 계산이 단순해서 학습이 빠르고 효율적입니다.\n",
    "기울기 소실 문제 해결: 다른 활성화 함수들에 비해 가 덜 발생합니다.\n",
    "\n",
    "이런 장점들 덕분에 ReLU는 특히 딥러닝에서 많이 사용\n",
    "\n",
    "## 옵티마이저 = 최적화 알고리즘\n",
    "\n",
    "Optimizer는 딥러닝 모델의 학습 과정에서 손실 함수를 최소화하기 위해 모델의 가중치를 조정하는 알고리즘입니다. 모델이 더 나은 예측을 할 수 있도록, 주어진 데이터와 손실 함수에 따라 가중치를 업데이트합니다. 대표적인 Optimizer로는 Stochastic Gradient Descent (SGD), Adam, RMSprop 등이 있습니다.\n",
    "\n",
    "\n",
    "간단히 말해, Optimizer는 딥러닝 모델을 더욱 효율적이고 정확하게 만드는 중요한 도구\n",
    "\n",
    "컴파일 메소드에서 SGD adam 여러가지를 써보면서, 검증세트를 통해서 가장 가장 잘맞는 옵티마이저를 정하는것이 중요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
